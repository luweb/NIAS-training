{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b1d05fc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-06T01:23:05.325231Z",
     "iopub.status.busy": "2022-01-06T01:23:05.317015Z",
     "iopub.status.idle": "2022-01-06T01:23:06.570026Z",
     "shell.execute_reply": "2022-01-06T01:23:06.569261Z",
     "shell.execute_reply.started": "2022-01-06T01:22:10.331252Z"
    },
    "papermill": {
     "duration": 1.272443,
     "end_time": "2022-01-06T01:23:06.570210",
     "exception": false,
     "start_time": "2022-01-06T01:23:05.297767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np #a. Numpy as np\n",
    "import pandas as pd #b. Pandas as pd\n",
    "import matplotlib.pyplot as plt #c. Matplotlib.pyplot\n",
    "import seaborn as sns #d. seaborne as sns\n",
    "%matplotlib inline\n",
    "np.random.seed(0) #f. Configurar o random seed para 0 (np.random.seed(0))\n",
    "\n",
    "#Importar os arquivos “kaggle/input/titanic/test.csv” e “kaggle/input/titanic/train.csv”\n",
    "titanic_data = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4253ac31",
   "metadata": {
    "papermill": {
     "duration": 0.013491,
     "end_time": "2022-01-06T01:23:06.598571",
     "exception": false,
     "start_time": "2022-01-06T01:23:06.585080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d361172",
   "metadata": {
    "papermill": {
     "duration": 0.013984,
     "end_time": "2022-01-06T01:23:06.625738",
     "exception": false,
     "start_time": "2022-01-06T01:23:06.611754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**1. Análise inicial:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eeb21df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T01:23:06.658021Z",
     "iopub.status.busy": "2022-01-06T01:23:06.657056Z",
     "iopub.status.idle": "2022-01-06T01:23:06.663845Z",
     "shell.execute_reply": "2022-01-06T01:23:06.663196Z",
     "shell.execute_reply.started": "2022-01-06T01:22:10.357076Z"
    },
    "papermill": {
     "duration": 0.024345,
     "end_time": "2022-01-06T01:23:06.664009",
     "exception": false,
     "start_time": "2022-01-06T01:23:06.639664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#a. Quais as colunas do banco de dados de teste e de treino\n",
    "print(titanic_data.columns)\n",
    "print(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b8f9f1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T01:23:06.695709Z",
     "iopub.status.busy": "2022-01-06T01:23:06.694923Z",
     "iopub.status.idle": "2022-01-06T01:23:06.701921Z",
     "shell.execute_reply": "2022-01-06T01:23:06.702806Z",
     "shell.execute_reply.started": "2022-01-06T01:22:10.364911Z"
    },
    "papermill": {
     "duration": 0.025108,
     "end_time": "2022-01-06T01:23:06.703077",
     "exception": false,
     "start_time": "2022-01-06T01:23:06.677969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "PassengerId      int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#b. Qual o tipo de dado de cada coluna nos dataframes de teste e de treino\n",
    "print(titanic_data.dtypes)\n",
    "print(test_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca208ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T01:23:06.735704Z",
     "iopub.status.busy": "2022-01-06T01:23:06.734815Z",
     "iopub.status.idle": "2022-01-06T01:23:06.746077Z",
     "shell.execute_reply": "2022-01-06T01:23:06.747176Z",
     "shell.execute_reply.started": "2022-01-06T01:22:10.379786Z"
    },
    "papermill": {
     "duration": 0.029371,
     "end_time": "2022-01-06T01:23:06.747541",
     "exception": false,
     "start_time": "2022-01-06T01:23:06.718170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#c. Qual a quantidade de valores nulos (NaN) em cada feature\n",
    "print(pd.isnull(titanic_data).sum())\n",
    "print(pd.isnull(test_data).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edda02d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T01:23:06.781739Z",
     "iopub.status.busy": "2022-01-06T01:23:06.780997Z",
     "iopub.status.idle": "2022-01-06T01:23:06.785051Z",
     "shell.execute_reply": "2022-01-06T01:23:06.785648Z",
     "shell.execute_reply.started": "2022-01-06T01:22:10.397553Z"
    },
    "papermill": {
     "duration": 0.023175,
     "end_time": "2022-01-06T01:23:06.785834",
     "exception": false,
     "start_time": "2022-01-06T01:23:06.762659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#d. Realizar um cópia do banco de dados de teste e de treino para que se possa fazer a manipulação sem perder informações\n",
    "titanic_data_clean = titanic_data.copy()\n",
    "test_data_clean = test_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b92eef3",
   "metadata": {
    "papermill": {
     "duration": 0.013819,
     "end_time": "2022-01-06T01:23:06.813955",
     "exception": false,
     "start_time": "2022-01-06T01:23:06.800136",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**2. Para lidar com valores nulos, podemos preencher estes valores de alguma forma ou descartar a informação. Neste item utilizaremos algumas estratégias para tal.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af05e246",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T01:23:06.846481Z",
     "iopub.status.busy": "2022-01-06T01:23:06.845710Z",
     "iopub.status.idle": "2022-01-06T01:23:06.878552Z",
     "shell.execute_reply": "2022-01-06T01:23:06.879152Z",
     "shell.execute_reply.started": "2022-01-06T01:22:10.404592Z"
    },
    "papermill": {
     "duration": 0.050988,
     "end_time": "2022-01-06T01:23:06.879361",
     "exception": false,
     "start_time": "2022-01-06T01:23:06.828373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n",
      "PassengerId    0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#a. A feature “Cabin” contém muitos valores nulos e, assim como “Ticket”, não fornece informações relevantes ao modelo à primeira vista. Então pode-se retirá-las.\n",
    "titanic_data_clean = titanic_data_clean.drop(['Cabin','Ticket'], axis=1)\n",
    "test_data_clean = test_data_clean.drop(['Cabin','Ticket'], axis=1)\n",
    "#b. A coluna “Age” também contém muitos valores nulos, mas dessa vez iremos preenchê-los. Utilizar a mediana dos valores de idade para isso, é uma boa estratégia inicial.\n",
    "titanic_data_clean['Age'].fillna(titanic_data_clean['Age'].median(), inplace = True)\n",
    "test_data_clean['Age'].fillna(test_data_clean['Age'].median(), inplace = True)\n",
    "#c. A feature “Fare” contém poucos valores nulos, e pode ser útil para análises futuras. Pode-se preenchê-la com a mesma estratégia que “Age”, já que ambas são contínuas.\n",
    "titanic_data_clean['Fare'].fillna(titanic_data_clean['Fare'].median(), inplace = True)\n",
    "test_data_clean['Fare'].fillna(test_data_clean['Fare'].median(), inplace = True)\n",
    "#d. Em “Embarked” também tem-se pouca ocorrência de valores nulos, e como é uma feature categórica, preencher com a moda parece menos impactante na construção do modelo.\n",
    "titanic_data_clean['Embarked'].fillna(titanic_data_clean['Embarked'].mode()[0], inplace = True)\n",
    "test_data_clean['Embarked'].fillna(test_data_clean['Embarked'].mode()[0], inplace = True)\n",
    "\n",
    "print(pd.isnull(titanic_data_clean).sum())\n",
    "print(pd.isnull(test_data_clean).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d084db12",
   "metadata": {
    "papermill": {
     "duration": 0.014452,
     "end_time": "2022-01-06T01:23:06.908411",
     "exception": false,
     "start_time": "2022-01-06T01:23:06.893959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**3. Para as Features contínuas será útil a criação de grupos para facilitar a análise. Dois métodos do pandas são úteis para esta tarefa, pd.cut e pd.qcut, também é útil visitar esta referência para uma melhor entendimento destes métodos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4a574f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T01:23:06.946191Z",
     "iopub.status.busy": "2022-01-06T01:23:06.942140Z",
     "iopub.status.idle": "2022-01-06T01:23:06.972442Z",
     "shell.execute_reply": "2022-01-06T01:23:06.971799Z",
     "shell.execute_reply.started": "2022-01-06T01:22:10.432689Z"
    },
    "papermill": {
     "duration": 0.049024,
     "end_time": "2022-01-06T01:23:06.972609",
     "exception": false,
     "start_time": "2022-01-06T01:23:06.923585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#a. Criar Feature que separe a Feature “Age” em 5 intervalos de mesma extensão.\n",
    "titanic_data_clean['AgeBin'] = pd.cut(titanic_data_clean['Age'].astype(int), 5)\n",
    "test_data_clean['AgeBin'] = pd.cut(test_data_clean['Age'].astype(int), 5)\n",
    "#b. Criar Feature que separe “Fare” em 6 intervalos que contenham o mesmo número de dados (Não precisam ter a mesma extensão).\n",
    "titanic_data_clean['FareBin'] = pd.qcut(titanic_data_clean['Fare'], 6)\n",
    "test_data_clean['FareBin'] = pd.qcut(test_data_clean['Fare'], 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573f0470",
   "metadata": {
    "papermill": {
     "duration": 0.014258,
     "end_time": "2022-01-06T01:23:07.001372",
     "exception": false,
     "start_time": "2022-01-06T01:23:06.987114",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Aperfeiçoamento da modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861e1f20",
   "metadata": {
    "papermill": {
     "duration": 0.014414,
     "end_time": "2022-01-06T01:23:07.030694",
     "exception": false,
     "start_time": "2022-01-06T01:23:07.016280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**1. Será necessário realizar o encoding das variáveis categóricas, no momento, 3 estratégias que serão utilizadas são o one-hot, label encoding e ordinal encoding. Para fazer isso será necessário relembrar quais são as features categóricas, definir a estratégia que será utilizada, criar as features codificadas e retirar as categóricas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afe8744e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T01:23:07.071839Z",
     "iopub.status.busy": "2022-01-06T01:23:07.070969Z",
     "iopub.status.idle": "2022-01-06T01:23:07.110960Z",
     "shell.execute_reply": "2022-01-06T01:23:07.111649Z",
     "shell.execute_reply.started": "2022-01-06T01:22:10.454284Z"
    },
    "papermill": {
     "duration": 0.06658,
     "end_time": "2022-01-06T01:23:07.111833",
     "exception": false,
     "start_time": "2022-01-06T01:23:07.045253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   PassengerId  891 non-null    int64   \n",
      " 1   Survived     891 non-null    int64   \n",
      " 2   Pclass       891 non-null    int64   \n",
      " 3   Sex          891 non-null    object  \n",
      " 4   SibSp        891 non-null    int64   \n",
      " 5   Parch        891 non-null    int64   \n",
      " 6   Embarked     891 non-null    object  \n",
      " 7   AgeBin       891 non-null    category\n",
      " 8   FareBin      891 non-null    category\n",
      "dtypes: category(2), int64(5), object(2)\n",
      "memory usage: 51.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>AgeBin</th>\n",
       "      <th>FareBin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>(-0.001, 7.775]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>(52.369, 512.329]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>(7.775, 8.662]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>(52.369, 512.329]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>(7.775, 8.662]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>(8.662, 14.454]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>(26.0, 52.369]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>(14.454, 26.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>male</td>\n",
       "      <td>C</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>(26.0, 52.369]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>male</td>\n",
       "      <td>Q</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>(-0.001, 7.775]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sex Embarked        AgeBin            FareBin\n",
       "0      male        S  (16.0, 32.0]    (-0.001, 7.775]\n",
       "1    female        C  (32.0, 48.0]  (52.369, 512.329]\n",
       "2    female        S  (16.0, 32.0]     (7.775, 8.662]\n",
       "3    female        S  (32.0, 48.0]  (52.369, 512.329]\n",
       "4      male        S  (32.0, 48.0]     (7.775, 8.662]\n",
       "..      ...      ...           ...                ...\n",
       "886    male        S  (16.0, 32.0]    (8.662, 14.454]\n",
       "887  female        S  (16.0, 32.0]     (26.0, 52.369]\n",
       "888  female        S  (16.0, 32.0]     (14.454, 26.0]\n",
       "889    male        C  (16.0, 32.0]     (26.0, 52.369]\n",
       "890    male        Q  (16.0, 32.0]    (-0.001, 7.775]\n",
       "\n",
       "[891 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acho que nao precisa dos nomes tbm\n",
    "titanic_data_clean = titanic_data_clean.drop(['Name','Fare','Age'], axis=1)\n",
    "test_data_clean = test_data_clean.drop(['Name','Fare','Age'], axis=1)\n",
    "\n",
    "#a. Utilizar o método “.info( )” para relembrar quais são as features categóricas.\n",
    "titanic_data_clean.info()\n",
    "\n",
    "#b. Utilizar o método “.select_dtypes” para identificar o nome das colunas numéricas e categóricas, \n",
    "#   para numéricas identifique formatos “int64” e “float64”, para categóricas identifique “Object”.\n",
    "titanic_data_clean.select_dtypes([\"category\", \"object\"])\n",
    "\n",
    "#c. Temos algumas features categóricas que contém uma ordem clara, ou seja, existe o primeiro valor, \n",
    "#   segundo valor, terceiro valor, assim por diante, já em outras, isso não acontece.\n",
    "#    i. Para as features que possuem ordem, o label encoder é mais indicado como primeira abordagem.\n",
    "#    ii. Para features sem ordem definida, one-hot encoding pode ser a melho opção.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6be6ad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T01:23:07.154748Z",
     "iopub.status.busy": "2022-01-06T01:23:07.145988Z",
     "iopub.status.idle": "2022-01-06T01:23:07.357848Z",
     "shell.execute_reply": "2022-01-06T01:23:07.357180Z",
     "shell.execute_reply.started": "2022-01-06T01:22:10.496325Z"
    },
    "papermill": {
     "duration": 0.230557,
     "end_time": "2022-01-06T01:23:07.358002",
     "exception": false,
     "start_time": "2022-01-06T01:23:07.127445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>AgeBin</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>x0_female</th>\n",
       "      <th>x0_male</th>\n",
       "      <th>x1_C</th>\n",
       "      <th>x1_Q</th>\n",
       "      <th>x1_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  SibSp  Parch  AgeBin  FareBin  x0_female  \\\n",
       "0            1         0       3      1      0       1        0        0.0   \n",
       "1            2         1       1      1      0       2        5        1.0   \n",
       "2            3         1       3      0      0       1        1        1.0   \n",
       "3            4         1       1      1      0       2        5        1.0   \n",
       "4            5         0       3      0      0       2        1        0.0   \n",
       "\n",
       "   x0_male  x1_C  x1_Q  x1_S  \n",
       "0      1.0   0.0   0.0   1.0  \n",
       "1      0.0   1.0   0.0   0.0  \n",
       "2      0.0   0.0   0.0   1.0  \n",
       "3      0.0   0.0   0.0   1.0  \n",
       "4      1.0   0.0   0.0   1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d. Criar uma função que realize o one-hot encode e, como saída, retorna um novo dataframe com as \n",
    "#   colunas que resultam da codificação, devidamente nomeadas, ao invés das features categóricas:\n",
    "#    i. Os argumentos deverão ser: o dataframe que será manipulado e as colunas que serão codificadas.\n",
    "#   ii. Realizar uma cópia do banco de dados que foi dado como argumento.\n",
    "#  iii. Criar um loop que realize o encoding das colunas presentes no argumento da função, as features \n",
    "#       resultantes devem conter o nome do valor que representam (OBS: utilizar o método \n",
    "#       “.get_feature_names”).\n",
    "#   iv. Ainda dentro do loop, retirar do dataframe copiado as features categóricas e mesclar as \n",
    "#       features criadas pelo one-hot encoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def one_hot_encode(df, columns=[]):\n",
    "    df_encoded = df.copy()\n",
    "    OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    OH_cols = pd.DataFrame(OH_encoder.fit_transform(df_encoded[columns]))\n",
    "    OH_cols.columns = OH_encoder.get_feature_names()\n",
    "    \n",
    "    # One-hot encoding removed index; put it back\n",
    "    OH_cols.index = df_encoded.index\n",
    "    \n",
    "    # Remove categorical columns (will replace with one-hot encoding)\n",
    "    df_encoded = df_encoded.drop(columns, axis=1)\n",
    "    \n",
    "    # Add one-hot encoded columns to numerical features\n",
    "    df_encoded = pd.concat([df_encoded, OH_cols], axis=1)\n",
    "    return df_encoded\n",
    "\n",
    "#e. Criar novas features para realizar o label encoding das features que contém um ordenamento claro, \n",
    "#   e depois retirar as features categóricas que foram codificadas.\n",
    "titanic_data_encoded = one_hot_encode(titanic_data_clean, [\"Sex\",\"Embarked\"])\n",
    "test_data_encoded = one_hot_encode(test_data_clean, [\"Sex\",\"Embarked\"])\n",
    "\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "titanic_data_encoded[\"AgeBin\"] = labelencoder.fit_transform(titanic_data_clean[\"AgeBin\"])\n",
    "titanic_data_encoded[\"FareBin\"] = labelencoder.fit_transform(titanic_data_clean[\"FareBin\"])\n",
    "\n",
    "test_data_encoded[\"AgeBin\"] = labelencoder.fit_transform(test_data_clean[\"AgeBin\"])\n",
    "test_data_encoded[\"FareBin\"] = labelencoder.fit_transform(test_data_clean[\"FareBin\"])\n",
    "\n",
    "titanic_data_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3838ed2",
   "metadata": {
    "papermill": {
     "duration": 0.015708,
     "end_time": "2022-01-06T01:23:07.389864",
     "exception": false,
     "start_time": "2022-01-06T01:23:07.374156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**3. Gerar predição, salvar a versão e submeter à competição**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10b3b4fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T01:23:07.430569Z",
     "iopub.status.busy": "2022-01-06T01:23:07.429613Z",
     "iopub.status.idle": "2022-01-06T01:23:07.998985Z",
     "shell.execute_reply": "2022-01-06T01:23:07.998390Z",
     "shell.execute_reply.started": "2022-01-06T01:22:10.545400Z"
    },
    "papermill": {
     "duration": 0.592298,
     "end_time": "2022-01-06T01:23:07.999158",
     "exception": false,
     "start_time": "2022-01-06T01:23:07.406860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#a. Treinar novamente o modelo, utilizando o banco de dados completo\n",
    "X = titanic_data_encoded.copy()\n",
    "y = X.pop(\"Survived\")\n",
    "\n",
    "randomforest = RandomForestClassifier()\n",
    "randomforest.fit(X, y)\n",
    "\n",
    "#b. Salvar o índice do banco de dados de teste\n",
    "ids = test_data_encoded['PassengerId']\n",
    "\n",
    "#c. Gerar uma predição a partir do modelo, sendo a entrar o banco de dados de teste, sem seu índice\n",
    "predictions = randomforest.predict(test_data_encoded)\n",
    "\n",
    "#d. Criar um dataframe com o pandas que contenha: os mesmos índices do banco de dados de teste, as predições realizadas (OBS: Olhar arquivo modelo \"gender_submission.csv\")\n",
    "output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\n",
    "\n",
    "#e. Transformar este dataframe em um arquivo csv utilizando pandas\n",
    "output.to_csv('submission.csv', index=False)\n",
    "\n",
    "#f. Salvar a versão clicando em “Save Version”, selecionar a versão que foi salva e submeter à competição"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.85693,
   "end_time": "2022-01-06T01:23:08.827673",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-06T01:22:53.970743",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
