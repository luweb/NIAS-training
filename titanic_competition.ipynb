{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação e visualização do banco de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Importar as bibliotecas que irão ser utilizadas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T23:44:29.732117Z",
     "iopub.status.busy": "2021-12-17T23:44:29.731808Z",
     "iopub.status.idle": "2021-12-17T23:44:29.739271Z",
     "shell.execute_reply": "2021-12-17T23:44:29.738300Z",
     "shell.execute_reply.started": "2021-12-17T23:44:29.732084Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np #a. Numpy as np\n",
    "import pandas as pd #b. Pandas as pd\n",
    "import matplotlib.pyplot as plt #c. Matplotlib.pyplot\n",
    "import seaborn as sns #d. seaborne as sns\n",
    "%matplotlib inline\n",
    "np.random.seed(0) #f. Configurar o random seed para 0 (np.random.seed(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Transformar arquivos em dataframe e gerar momentos estatísticos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T23:44:32.531645Z",
     "iopub.status.busy": "2021-12-17T23:44:32.531370Z",
     "iopub.status.idle": "2021-12-17T23:44:32.585931Z",
     "shell.execute_reply": "2021-12-17T23:44:32.585112Z",
     "shell.execute_reply.started": "2021-12-17T23:44:32.531613Z"
    }
   },
   "outputs": [],
   "source": [
    "#a. Importar os arquivos “kaggle/input/titanic/test.csv” e “kaggle/input/titanic/train.csv”\n",
    "titanic_data = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/titanic/test.csv')\n",
    "#b. Gerar momentos estatísticos sobre o dataframe de treino, utilizando “.describe( )”\n",
    "titanic_data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Análise dos dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T23:44:35.007051Z",
     "iopub.status.busy": "2021-12-17T23:44:35.006374Z",
     "iopub.status.idle": "2021-12-17T23:44:35.031600Z",
     "shell.execute_reply": "2021-12-17T23:44:35.030802Z",
     "shell.execute_reply.started": "2021-12-17T23:44:35.007011Z"
    }
   },
   "outputs": [],
   "source": [
    "#a. Identificar as Features do banco de dados que são categóricas (não numéricas), e as que são numéricas. As numéricas, deve-se separá-las em discretas e contínuas.\n",
    "#  i. Pode-se usar o método “.info( )” para descobrir o tipo de dado de cada Feature.\n",
    "print(test_data.info())\n",
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T23:44:37.672197Z",
     "iopub.status.busy": "2021-12-17T23:44:37.671909Z",
     "iopub.status.idle": "2021-12-17T23:44:37.679513Z",
     "shell.execute_reply": "2021-12-17T23:44:37.678874Z",
     "shell.execute_reply.started": "2021-12-17T23:44:37.672165Z"
    }
   },
   "outputs": [],
   "source": [
    "#b. Descobrir quais as Features contém NaN, além da quantidade desse tipo de dado em cada Feature.\n",
    "#  i. Pode-se utilizar o comando “DataFrame.isnull.sum( )”\n",
    "print(pd.isnull(titanic_data).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T23:44:41.375107Z",
     "iopub.status.busy": "2021-12-17T23:44:41.374818Z",
     "iopub.status.idle": "2021-12-17T23:44:41.385783Z",
     "shell.execute_reply": "2021-12-17T23:44:41.384873Z",
     "shell.execute_reply.started": "2021-12-17T23:44:41.375078Z"
    }
   },
   "outputs": [],
   "source": [
    "#c. Deve-se utilizar apenas Features numéricas e retirar as categóricas. Portanto, faça dois novos dataframes, apenas com as features numéricas do banco de dados de treino e de teste.\n",
    "titanic_data_num = titanic_data[['PassengerId','Age', 'Fare', 'SibSp', 'Parch', 'Survived']]\n",
    "test_data_num = test_data[['PassengerId','Age', 'Fare', 'SibSp', 'Parch']]\n",
    "\n",
    "#d. Retire as linhas que contenham NaN das features do banco de dados de treino.\n",
    "#  i. Para isso será útil o método DataFrame.dropna( )\n",
    "titanic_data_num = titanic_data_num.dropna( )\n",
    "\n",
    "#e. no banco de dados de teste, substitua os NaN pelo valor 0, para que o arquivo de predição tenha o número de linhas exigido pela competição\n",
    "#  i. Utilizar o método DataFrame.fillna( )\n",
    "test_data_num = test_data_num.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Exploração do banco de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Para a Feature “Age” será necessário criar uma nova Feature que a separe em 8 grupos para que se possa utilizar “sns.barplot”. (DICA: Crie um novo dataframe apenas com as informações necessárias para a criação deste gráfico)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T23:44:46.401997Z",
     "iopub.status.busy": "2021-12-17T23:44:46.401676Z",
     "iopub.status.idle": "2021-12-17T23:44:46.898541Z",
     "shell.execute_reply": "2021-12-17T23:44:46.897626Z",
     "shell.execute_reply.started": "2021-12-17T23:44:46.401965Z"
    }
   },
   "outputs": [],
   "source": [
    "#a. Criar uma lista com os nomes que serão dados aos grupos em que as idades serão repartidas (Exemplo: “(0-10)”, “(10-20)”, ...)\n",
    "bins = [0, 5, 10, 15, 20, 25, 35, 45, 60, np.inf]\n",
    "labels = ['(0-5)', '(5-10)', '(10-15)', '(15-20)', '(20-25)', '(25-35)', '(35-45)','(45-60)', 'Idoso']\n",
    "\n",
    "#b. utilize pandas.cut, para separar as idades em 8 grupos e utilize o argumento “labels” para utilizar a lista dos nomes dos grupos\n",
    "#c. Criar a nova coluna com os grupos, perceba que esta nova coluna será categórica\n",
    "titanic_data_num['AgeGroup'] = pd.cut(titanic_data_num[\"Age\"], bins, labels = labels)\n",
    "test_data_num['AgeGroup'] = pd.cut(test_data_num[\"Age\"], bins, labels = labels)\n",
    "\n",
    "#d. Criar um gráfico que indique a chance de sobrevivência por grupo de idade\n",
    "sns.barplot(x=\"AgeGroup\", y=\"Survived\", data=titanic_data_num)\n",
    "plt.show()\n",
    "\n",
    "#e. Faça uma análise a partir da visualização deste gráfico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crianças de 0-5 anos tem a mais alta taxa de sobrevivencia enquanto idosos tem a menor taxa de sobrevivencia, o que é esperado. As taxas de sobrevivencia dos outros grupos são contra intuitivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Crie gráficos para todas as outras features numéricas discretas, e faça uma análise dos resultados obtidos. Não será necessário produzir um gráfico para a feature “Fare”. Após a criação de cada gráfico será necessário realizar uma breve análise para avaliação do impacto de cada feature na predição**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T23:44:52.798523Z",
     "iopub.status.busy": "2021-12-17T23:44:52.797577Z",
     "iopub.status.idle": "2021-12-17T23:44:53.193538Z",
     "shell.execute_reply": "2021-12-17T23:44:53.192691Z",
     "shell.execute_reply.started": "2021-12-17T23:44:52.798460Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Parch\", y=\"Survived\", data=titanic_data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T23:44:55.377623Z",
     "iopub.status.busy": "2021-12-17T23:44:55.377346Z",
     "iopub.status.idle": "2021-12-17T23:44:55.769421Z",
     "shell.execute_reply": "2021-12-17T23:44:55.768831Z",
     "shell.execute_reply.started": "2021-12-17T23:44:55.377591Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=\"SibSp\", y=\"Survived\", data=titanic_data_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento do modelo e submissão das predições"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Separação de banco de dados de treino e validação.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T23:45:05.144307Z",
     "iopub.status.busy": "2021-12-17T23:45:05.143612Z",
     "iopub.status.idle": "2021-12-17T23:45:05.153836Z",
     "shell.execute_reply": "2021-12-17T23:45:05.152819Z",
     "shell.execute_reply.started": "2021-12-17T23:45:05.144266Z"
    }
   },
   "outputs": [],
   "source": [
    "#a. Criar variável X, contendo o banco de dados apenas das Features\n",
    "X = titanic_data_num.drop(['PassengerId','Survived', 'AgeGroup'], axis=1)\n",
    "\n",
    "#b. Criar variável y, contendo o target da predição\n",
    "y = titanic_data_num[\"Survived\"]\n",
    "\n",
    "#c. Usar Train Test Split para separar treino e validação (DICA: utilizar validação com 20% do tamanho do treino)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Treinamento e validação do modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T23:45:09.830350Z",
     "iopub.status.busy": "2021-12-17T23:45:09.830098Z",
     "iopub.status.idle": "2021-12-17T23:45:10.072143Z",
     "shell.execute_reply": "2021-12-17T23:45:10.071307Z",
     "shell.execute_reply.started": "2021-12-17T23:45:09.830322Z"
    }
   },
   "outputs": [],
   "source": [
    "#a. Importar Random Forest Classifier da biblioteca sklearn.ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#b. Importar accuracy score da biblioteca sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#c. Treinar random forest com as features e o target de treino\n",
    "randomforest = RandomForestClassifier()\n",
    "randomforest.fit(x_train, y_train)\n",
    "\n",
    "#d. Realizar a predição\n",
    "y_pred = randomforest.predict(x_val)\n",
    "\n",
    "#e. Validar a predição, comparando com o target da validação, utilizando accuracy score\n",
    "acc_randomforest = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_randomforest)\n",
    "\n",
    "#f. Avalie se a pontuação é satisfatória\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maior que 50%, mas com certeza da pra melhorar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Gerar predição, salvar a versão e submeter à competição**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T23:45:44.373306Z",
     "iopub.status.busy": "2021-12-17T23:45:44.372545Z",
     "iopub.status.idle": "2021-12-17T23:45:44.637338Z",
     "shell.execute_reply": "2021-12-17T23:45:44.636719Z",
     "shell.execute_reply.started": "2021-12-17T23:45:44.373261Z"
    }
   },
   "outputs": [],
   "source": [
    "#a. Treinar novamente o modelo, utilizando o banco de dados completo\n",
    "randomforest = RandomForestClassifier()\n",
    "randomforest.fit(X, y)\n",
    "\n",
    "#b. Salvar o índice do banco de dados de teste\n",
    "ids = test_data_num['PassengerId']\n",
    "\n",
    "#c. Gerar uma predição a partir do modelo, sendo a entrar o banco de dados de teste, sem seu índice\n",
    "predictions = randomforest.predict(test_data_num.drop(['PassengerId','AgeGroup'], axis=1))\n",
    "\n",
    "#d. Criar um dataframe com o pandas que contenha: os mesmos índices do banco de dados de teste, as predições realizadas (OBS: Olhar arquivo modelo \"gender_submission.csv\")\n",
    "output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\n",
    "\n",
    "#e. Transformar este dataframe em um arquivo csv utilizando pandas\n",
    "output.to_csv('submission.csv', index=False)\n",
    "\n",
    "#f. Salvar a versão clicando em “Save Version”, selecionar a versão que foi salva e submeter à competição"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
